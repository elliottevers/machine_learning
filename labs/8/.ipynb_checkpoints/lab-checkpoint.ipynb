{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "%% Machine Learning Online Class\n",
    "%  Exercise 7 | Principle Component Analysis and K-Means Clustering\n",
    "%\n",
    "%  Instructions\n",
    "%  ------------\n",
    "%\n",
    "%  This file contains code that helps you get started on the\n",
    "%  exercise. You will need to complete the following functions:\n",
    "%\n",
    "%     pca.m\n",
    "%     projectData.m\n",
    "%     recoverData.m\n",
    "%     computeCentroids.m\n",
    "%     findClosestCentroids.m\n",
    "%     kMeansInitCentroids.m\n",
    "%\n",
    "%  For this exercise, you will not need to change any code in this file,\n",
    "%  or any other files other than those mentioned above.\n",
    "%\n",
    "\n",
    "%% Initialization\n",
    "clear ; close all; clc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "%plot gnuplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "function idx = findClosestCentroids(X, centroids)\n",
    "%FINDCLOSESTCENTROIDS computes the centroid memberships for every example\n",
    "%   idx = FINDCLOSESTCENTROIDS (X, centroids) returns the closest centroids\n",
    "%   in idx for a dataset X where each row is a single example. idx = m x 1 \n",
    "%   vector of centroid assignments (i.e. each entry in range [1..K])\n",
    "%\n",
    "\n",
    "% Set K\n",
    "K = size(centroids, 1);\n",
    "\n",
    "% You need to return the following variables correctly.\n",
    "idx = zeros(size(X,1), 1);\n",
    "\n",
    "% ====================== YOUR CODE HERE ======================\n",
    "% Instructions: Go over every example, find its closest centroid, and store\n",
    "%               the index inside idx at the appropriate location.\n",
    "%               Concretely, idx(i) should contain the index of the centroid\n",
    "%               closest to example i. Hence, it should be a value in the \n",
    "%               range 1..K\n",
    "%\n",
    "% Note: You can use a for-loop over the examples to compute this.\n",
    "%\n",
    "\n",
    "\n",
    "for i = 1:size(X, 1)\n",
    "    min_distance = Inf;\n",
    "    min_index = Inf;\n",
    "    for j = 1:K\n",
    "        dist = norm(X(i, :) - centroids(j, :));\n",
    "        if dist < min_distance\n",
    "            min_distance = dist;\n",
    "            min_index = j;\n",
    "        end\n",
    "    end\n",
    "    idx(i) = min_index;\n",
    "end\n",
    "\n",
    "% =============================================================\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding closest centroids.\n",
      "\n",
      "warning: load: '/Users/elliottevers/Documents/git-repos.nosync/machine_learning/labs/8/machine-learning-ex7/ex7/ex7data2.mat' found by searching load path\n",
      "Closest centroids for the first 3 examples: \n",
      " 1 3 2\n",
      "\n",
      "(the closest centroids should be 1, 3, 2 respectively)\n",
      " 1 3 2\n"
     ]
    }
   ],
   "source": [
    "%% ================= Part 1: Find Closest Centroids ====================\n",
    "%  To help you implement K-Means, we have divided the learning algorithm \n",
    "%  into two functions -- findClosestCentroids and computeCentroids. In this\n",
    "%  part, you should complete the code in the findClosestCentroids function. \n",
    "%\n",
    "fprintf('Finding closest centroids.\\n\\n');\n",
    "\n",
    "dir_materials = '/Users/elliottevers/Documents/git-repos.nosync/machine_learning/labs/8/machine-learning-ex7/ex7/';\n",
    "addpath(dir_materials);\n",
    "% Load an example dataset that we will be using\n",
    "load('ex7data2.mat');\n",
    "\n",
    "% Select an initial set of centroids\n",
    "K = 3; % 3 Centroids\n",
    "initial_centroids = [3 3; 6 2; 8 5];\n",
    "\n",
    "% Find the closest centroids for the examples using the\n",
    "% initial_centroids\n",
    "% dbstop in findClosestCentroids 37\n",
    "idx = findClosestCentroids(X, initial_centroids);\n",
    "\n",
    "fprintf('Closest centroids for the first 3 examples: \\n')\n",
    "fprintf(' %d', idx(1:3));\n",
    "fprintf('\\n(the closest centroids should be 1, 3, 2 respectively)\\n');\n",
    "\n",
    "% fprintf('Program paused. Press enter to continue.\\n');\n",
    "% pause;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "function centroids = computeCentroids(X, idx, K)\n",
    "%COMPUTECENTROIDS returns the new centroids by computing the means of the \n",
    "%data points assigned to each centroid.\n",
    "%   centroids = COMPUTECENTROIDS(X, idx, K) returns the new centroids by \n",
    "%   computing the means of the data points assigned to each centroid. It is\n",
    "%   given a dataset X where each row is a single data point, a vector\n",
    "%   idx of centroid assignments (i.e. each entry in range [1..K]) for each\n",
    "%   example, and K, the number of centroids. You should return a matrix\n",
    "%   centroids, where each row of centroids is the mean of the data points\n",
    "%   assigned to it.\n",
    "%\n",
    "\n",
    "% Useful variables\n",
    "[m n] = size(X);\n",
    "\n",
    "% You need to return the following variables correctly.\n",
    "centroids = zeros(K, n);\n",
    "\n",
    "\n",
    "% ====================== YOUR CODE HERE ======================\n",
    "% Instructions: Go over every centroid and compute mean of all points that\n",
    "%               belong to it. Concretely, the row vector centroids(i, :)\n",
    "%               should contain the mean of the data points assigned to\n",
    "%               centroid i.\n",
    "%\n",
    "% Note: You can use a for-loop over the centroids to compute this.\n",
    "%\n",
    "\n",
    "\n",
    "for k=1:K\n",
    "   centroids(k, :) = mean(\n",
    "       X(idx==k, :)\n",
    "   );\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "% =============================================================\n",
    "\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing centroids means.\n",
      "\n",
      "Centroids computed after initial finding of closest centroids: \n",
      " 2.428301 3.157924 \n",
      " 5.813503 2.633656 \n",
      " 7.119387 3.616684 \n",
      "\n",
      "(the centroids should be\n",
      "   [ 2.428301 3.157924 ]\n",
      "   [ 5.813503 2.633656 ]\n",
      "   [ 7.119387 3.616684 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%% ===================== Part 2: Compute Means =========================\n",
    "%  After implementing the closest centroids function, you should now\n",
    "%  complete the computeCentroids function.\n",
    "%\n",
    "fprintf('\\nComputing centroids means.\\n\\n');\n",
    "\n",
    "%  Compute means based on the closest centroids found in the previous part.\n",
    "centroids = computeCentroids(X, idx, K);\n",
    "\n",
    "fprintf('Centroids computed after initial finding of closest centroids: \\n')\n",
    "fprintf(' %f %f \\n' , centroids');\n",
    "fprintf('\\n(the centroids should be\\n');\n",
    "fprintf('   [ 2.428301 3.157924 ]\\n');\n",
    "fprintf('   [ 5.813503 2.633656 ]\\n');\n",
    "fprintf('   [ 7.119387 3.616684 ]\\n\\n');\n",
    "\n",
    "% fprintf('Program paused. Press enter to continue.\\n');\n",
    "% pause;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running K-Means clustering on example dataset.\n",
      "\n",
      "warning: load: '/Users/elliottevers/Documents/git-repos.nosync/machine_learning/labs/8/machine-learning-ex7/ex7/ex7data2.mat' found by searching load path\n",
      "K-Means iteration 1/10...\n",
      "Press enter to continue.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Paused, enter any value to continue p\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 'p' undefined near line 1 column 1\n",
      "error: called from\n",
      "    input at line 43 column 9\n",
      "    pause at line 23 column 9\n",
      "    runkMeans at line 51 column 9\n",
      "\n",
      "K-Means Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%% =================== Part 3: K-Means Clustering ======================\n",
    "%  After you have completed the two functions computeCentroids and\n",
    "%  findClosestCentroids, you have all the necessary pieces to run the\n",
    "%  kMeans algorithm. In this part, you will run the K-Means algorithm on\n",
    "%  the example dataset we have provided. \n",
    "%\n",
    "fprintf('\\nRunning K-Means clustering on example dataset.\\n\\n');\n",
    "\n",
    "% Load an example dataset\n",
    "load('ex7data2.mat');\n",
    "\n",
    "% Settings for running K-Means\n",
    "K = 3;\n",
    "max_iters = 10;\n",
    "\n",
    "% For consistency, here we set centroids to specific values\n",
    "% but in practice you want to generate them automatically, such as by\n",
    "% settings them to be random examples (as can be seen in\n",
    "% kMeansInitCentroids).\n",
    "initial_centroids = [3 3; 6 2; 8 5];\n",
    "\n",
    "% Run K-Means algorithm. The 'true' at the end tells our function to plot\n",
    "% the progress of K-Means\n",
    "[centroids, idx] = runkMeans(X, initial_centroids, max_iters, true);\n",
    "fprintf('\\nK-Means Done.\\n\\n');\n",
    "\n",
    "% fprintf('Program paused. Press enter to continue.\\n');\n",
    "% pause;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "function centroids = kMeansInitCentroids(X, K)\n",
    "%KMEANSINITCENTROIDS This function initializes K centroids that are to be \n",
    "%used in K-Means on the dataset X\n",
    "%   centroids = KMEANSINITCENTROIDS(X, K) returns K initial centroids to be\n",
    "%   used with the K-Means on the dataset X\n",
    "%\n",
    "\n",
    "% You should return this values correctly\n",
    "centroids = zeros(K, size(X, 2));\n",
    "\n",
    "% ====================== YOUR CODE HERE ======================\n",
    "% Instructions: You should set centroids to randomly chosen examples from\n",
    "%               the dataset X\n",
    "%\n",
    "\n",
    "\n",
    "\n",
    "% Initialize the centroids to be random examples\n",
    "% Randomly reorder the indices of examples\n",
    "randidx = randperm(size(X, 1));\n",
    "% Take the first K examples as centroids\n",
    "centroids = X(randidx(1:K), :);\n",
    "\n",
    "\n",
    "\n",
    "% =============================================================\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "%% ============= Part 4: K-Means Clustering on Pixels ===============\n",
    "%  In this exercise, you will use K-Means to compress an image. To do this,\n",
    "%  you will first run K-Means on the colors of the pixels in the image and\n",
    "%  then you will map each pixel onto its closest centroid.\n",
    "%  \n",
    "%  You should now complete the code in kMeansInitCentroids.m\n",
    "%\n",
    "\n",
    "fprintf('\\nRunning K-Means clustering on pixels from an image.\\n\\n');\n",
    "\n",
    "%  Load an image of a bird\n",
    "% A = double(imread('bird_small.png'));\n",
    "A = double(imread(strcat(dir_materials, 'bird_small.png')));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans =\n",
      "\n",
      "   0.85882   0.70588   0.40392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X(1, :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running K-Means clustering on pixels from an image.\n",
      "\n",
      "K-Means iteration 1/10...\n",
      "K-Means iteration 2/10...\n",
      "K-Means iteration 3/10...\n",
      "K-Means iteration 4/10...\n",
      "K-Means iteration 5/10...\n",
      "K-Means iteration 6/10...\n",
      "K-Means iteration 7/10...\n",
      "K-Means iteration 8/10...\n",
      "K-Means iteration 9/10...\n",
      "K-Means iteration 10/10...\n"
     ]
    }
   ],
   "source": [
    "% If imread does not work for you, you can try instead\n",
    "%   load ('bird_small.mat');\n",
    "\n",
    "A = A / 255; % Divide by 255 so that all values are in the range 0 - 1\n",
    "\n",
    "% Size of the image\n",
    "img_size = size(A);\n",
    "\n",
    "% Reshape the image into an Nx3 matrix where N = number of pixels.\n",
    "% Each row will contain the Red, Green and Blue pixel values\n",
    "% This gives us our dataset matrix X that we will use K-Means on.\n",
    "X = reshape(A, img_size(1) * img_size(2), 3);\n",
    "\n",
    "% Run your K-Means algorithm on this data\n",
    "% You should try different values of K and max_iters here\n",
    "K = 16; \n",
    "max_iters = 10;\n",
    "\n",
    "% When using K-Means, it is important the initialize the centroids\n",
    "% randomly. \n",
    "% You should complete the code in kMeansInitCentroids.m before proceeding\n",
    "initial_centroids = kMeansInitCentroids(X, K);\n",
    "\n",
    "% Run K-Means\n",
    "[centroids, idx] = runkMeans(X, initial_centroids, max_iters);\n",
    "\n",
    "% fprintf('Program paused. Press enter to continue.\\n');\n",
    "% pause;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying K-Means to compress an image.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%% ================= Part 5: Image Compression ======================\n",
    "%  In this part of the exercise, you will use the clusters of K-Means to\n",
    "%  compress an image. To do this, we first find the closest clusters for\n",
    "%  each example. After that, we \n",
    "\n",
    "fprintf('\\nApplying K-Means to compress an image.\\n\\n');\n",
    "\n",
    "% Find closest cluster members\n",
    "idx = findClosestCentroids(X, centroids);\n",
    "\n",
    "% Essentially, now we have represented the image X as in terms of the\n",
    "% indices in idx. \n",
    "\n",
    "% We can now recover the image from the indices (idx) by mapping each pixel\n",
    "% (specified by its index in idx) to the centroid value\n",
    "X_recovered = centroids(idx,:);\n",
    "\n",
    "% Reshape the recovered image into proper dimensions\n",
    "X_recovered = reshape(X_recovered, img_size(1), img_size(2), 3);\n",
    "\n",
    "% Display the original image \n",
    "subplot(1, 2, 1);\n",
    "imagesc(A); \n",
    "title('Original');\n",
    "\n",
    "% Display compressed image side by side\n",
    "subplot(1, 2, 2);\n",
    "imagesc(X_recovered)\n",
    "title(sprintf('Compressed, with %d colors.', K));\n",
    "\n",
    "\n",
    "% fprintf('Program paused. Press enter to continue.\\n');\n",
    "% pause;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "%% Machine Learning Online Class\n",
    "%  Exercise 7 | Principle Component Analysis and K-Means Clustering\n",
    "%\n",
    "%  Instructions\n",
    "%  ------------\n",
    "%\n",
    "%  This file contains code that helps you get started on the\n",
    "%  exercise. You will need to complete the following functions:\n",
    "%\n",
    "%     pca.m\n",
    "%     projectData.m\n",
    "%     recoverData.m\n",
    "%     computeCentroids.m\n",
    "%     findClosestCentroids.m\n",
    "%     kMeansInitCentroids.m\n",
    "%\n",
    "%  For this exercise, you will not need to change any code in this file,\n",
    "%  or any other files other than those mentioned above.\n",
    "%\n",
    "\n",
    "%% Initialization\n",
    "clear ; close all; clc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing example dataset for PCA.\n",
      "\n",
      "warning: load: '/Users/elliottevers/Documents/git-repos.nosync/machine_learning/labs/8/machine-learning-ex7/ex7/ex7data1.mat' found by searching load path\n"
     ]
    }
   ],
   "source": [
    "%% ================== Part 1: Load Example Dataset  ===================\n",
    "%  We start this exercise by using a small dataset that is easily to\n",
    "%  visualize\n",
    "%\n",
    "fprintf('Visualizing example dataset for PCA.\\n\\n');\n",
    "\n",
    "%  The following command loads the dataset. You should now have the \n",
    "%  variable X in your environment\n",
    "load ('ex7data1.mat');\n",
    "\n",
    "%  Visualize the example dataset\n",
    "plot(X(:, 1), X(:, 2), 'bo');\n",
    "axis([0.5 6.5 2 8]); axis square;\n",
    "\n",
    "% fprintf('Program paused. Press enter to continue.\\n');\n",
    "% pause;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "function [U, S] = pca(X)\n",
    "%PCA Run principal component analysis on the dataset X\n",
    "%   [U, S, X] = pca(X) computes eigenvectors of the covariance matrix of X\n",
    "%   Returns the eigenvectors U, the eigenvalues (on diagonal) in S\n",
    "%\n",
    "\n",
    "% Useful values\n",
    "[m, n] = size(X);\n",
    "\n",
    "% You need to return the following variables correctly.\n",
    "U = zeros(n);\n",
    "S = zeros(n);\n",
    "\n",
    "% ====================== YOUR CODE HERE ======================\n",
    "% Instructions: You should first compute the covariance matrix. Then, you\n",
    "%               should use the \"svd\" function to compute the eigenvectors\n",
    "%               and eigenvalues of the covariance matrix. \n",
    "%\n",
    "% Note: When computing the covariance matrix, remember to divide by m (the\n",
    "%       number of examples).\n",
    "%\n",
    "\n",
    "\n",
    "\n",
    "Sigma = (1/m)*X'*X;\n",
    "\n",
    "[U, S, V] = svd(Sigma);\n",
    "\n",
    "% =========================================================================\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running PCA on example dataset.\n",
      "\n",
      "Top eigenvector: \n",
      " U(:,1) = -0.707107 -0.707107 \n",
      "\n",
      "(you should expect to see -0.707107 -0.707107)\n"
     ]
    }
   ],
   "source": [
    "%% =============== Part 2: Principal Component Analysis ===============\n",
    "%  You should now implement PCA, a dimension reduction technique. You\n",
    "%  should complete the code in pca.m\n",
    "%\n",
    "fprintf('\\nRunning PCA on example dataset.\\n\\n');\n",
    "\n",
    "%  Before running PCA, it is important to first normalize X\n",
    "[X_norm, mu, sigma] = featureNormalize(X);\n",
    "\n",
    "%  Run PCA\n",
    "[U, S] = pca(X_norm);\n",
    "\n",
    "%  Compute mu, the mean of the each feature\n",
    "\n",
    "%  Draw the eigenvectors centered at mean of data. These lines show the\n",
    "%  directions of maximum variations in the dataset.\n",
    "hold on;\n",
    "drawLine(mu, mu + 1.5 * S(1,1) * U(:,1)', '-k', 'LineWidth', 2);\n",
    "drawLine(mu, mu + 1.5 * S(2,2) * U(:,2)', '-k', 'LineWidth', 2);\n",
    "hold off;\n",
    "\n",
    "fprintf('Top eigenvector: \\n');\n",
    "fprintf(' U(:,1) = %f %f \\n', U(1,1), U(2,1));\n",
    "fprintf('\\n(you should expect to see -0.707107 -0.707107)\\n');\n",
    "\n",
    "% fprintf('Program paused. Press enter to continue.\\n');\n",
    "% pause;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "function Z = projectData(X, U, K)\n",
    "%PROJECTDATA Computes the reduced data representation when projecting only \n",
    "%on to the top k eigenvectors\n",
    "%   Z = projectData(X, U, K) computes the projection of \n",
    "%   the normalized inputs X into the reduced dimensional space spanned by\n",
    "%   the first K columns of U. It returns the projected examples in Z.\n",
    "%\n",
    "\n",
    "% You need to return the following variables correctly.\n",
    "Z = zeros(size(X, 1), K);\n",
    "\n",
    "% ====================== YOUR CODE HERE ======================\n",
    "% Instructions: Compute the projection of the data using only the top K \n",
    "%               eigenvectors in U (first K columns). \n",
    "%               For the i-th example X(i,:), the projection on to the k-th \n",
    "%               eigenvector is given as follows:\n",
    "%                    x = X(i, :)';\n",
    "%                    projection_k = x' * U(:, k);\n",
    "%\n",
    "\n",
    "for i = 1:size(X, 1)\n",
    "    proj = 0;\n",
    "    for k = 1:K\n",
    "        x = X(i, :)';\n",
    "        proj = proj + (x' * U(:, k));\n",
    "    end\n",
    "    Z(i, :) = proj;\n",
    "end\n",
    "\n",
    "% =============================================================\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "function X_rec = recoverData(Z, U, K)\n",
    "%RECOVERDATA Recovers an approximation of the original data when using the \n",
    "%projected data\n",
    "%   X_rec = RECOVERDATA(Z, U, K) recovers an approximation the \n",
    "%   original data that has been reduced to K dimensions. It returns the\n",
    "%   approximate reconstruction in X_rec.\n",
    "%\n",
    "\n",
    "% You need to return the following variables correctly.\n",
    "X_rec = zeros(size(Z, 1), size(U, 1));\n",
    "\n",
    "% ====================== YOUR CODE HERE ======================\n",
    "% Instructions: Compute the approximation of the data by projecting back\n",
    "%               onto the original space using the top K eigenvectors in U.\n",
    "%\n",
    "%               For the i-th example Z(i,:), the (approximate)\n",
    "%               recovered data for dimension j is given as follows:\n",
    "%                    v = Z(i, :)';\n",
    "%                    recovered_j = v' * U(j, 1:K)';\n",
    "%\n",
    "%               Notice that U(j, 1:K) is a row vector.\n",
    "%               \n",
    "\n",
    "for i=1:size(Z, 1)\n",
    "\n",
    "    recovered_proj = 0;\n",
    "    \n",
    "    for k = 1:K\n",
    "        v = Z(i, :)';\n",
    "        recovered_proj = recovered_proj + v' * U(j, 1:K)';\n",
    "    end\n",
    "    \n",
    "    X_rec(i, :) = recovered_proj;\n",
    "end\n",
    "\n",
    "% =============================================================\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dimension reduction on example dataset.\n",
      "\n",
      "Projection of the first example: 1.481274\n",
      "\n",
      "(this value should be about 1.481274)\n",
      "\n",
      "error: U(0+1i,_): subscripts must be real (forgot to initialize i or j?)\n",
      "error: called from\n",
      "    recoverData at line 30 column 24\n",
      "Approximation of the first example: -1.047419 -1.047419\n",
      "\n",
      "(this value should be about  -1.047419 -1.047419)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%% =================== Part 3: Dimension Reduction ===================\n",
    "%  You should now implement the projection step to map the data onto the \n",
    "%  first k eigenvectors. The code will then plot the data in this reduced \n",
    "%  dimensional space.  This will show you what the data looks like when \n",
    "%  using only the corresponding eigenvectors to reconstruct it.\n",
    "%\n",
    "%  You should complete the code in projectData.m\n",
    "%\n",
    "fprintf('\\nDimension reduction on example dataset.\\n\\n');\n",
    "\n",
    "%  Plot the normalized dataset (returned from pca)\n",
    "plot(X_norm(:, 1), X_norm(:, 2), 'bo');\n",
    "axis([-4 3 -4 3]); axis square\n",
    "\n",
    "%  Project the data onto K = 1 dimension\n",
    "K = 1;\n",
    "Z = projectData(X_norm, U, K);\n",
    "fprintf('Projection of the first example: %f\\n', Z(1));\n",
    "fprintf('\\n(this value should be about 1.481274)\\n\\n');\n",
    "\n",
    "X_rec  = recoverData(Z, U, K);\n",
    "fprintf('Approximation of the first example: %f %f\\n', X_rec(1, 1), X_rec(1, 2));\n",
    "fprintf('\\n(this value should be about  -1.047419 -1.047419)\\n\\n');\n",
    "\n",
    "%  Draw lines connecting the projected points to the original points\n",
    "hold on;\n",
    "plot(X_rec(:, 1), X_rec(:, 2), 'ro');\n",
    "for i = 1:size(X_norm, 1)\n",
    "    drawLine(X_norm(i,:), X_rec(i,:), '--k', 'LineWidth', 1);\n",
    "end\n",
    "hold off\n",
    "\n",
    "% fprintf('Program paused. Press enter to continue.\\n');\n",
    "% pause;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading face dataset.\n",
      "\n",
      "warning: load: '/Users/elliottevers/Documents/git-repos.nosync/machine_learning/labs/8/machine-learning-ex7/ex7/ex7faces.mat' found by searching load path\n"
     ]
    }
   ],
   "source": [
    "%% =============== Part 4: Loading and Visualizing Face Data =============\n",
    "%  We start the exercise by first loading and visualizing the dataset.\n",
    "%  The following code will load the dataset into your environment\n",
    "%\n",
    "fprintf('\\nLoading face dataset.\\n\\n');\n",
    "\n",
    "%  Load Face dataset\n",
    "load ('ex7faces.mat')\n",
    "\n",
    "%  Display the first 100 faces in the dataset\n",
    "displayData(X(1:100, :));\n",
    "\n",
    "% fprintf('Program paused. Press enter to continue.\\n');\n",
    "% pause;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running PCA on face dataset.\n",
      "(this might take a minute or two ...)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%% =========== Part 5: PCA on Face Data: Eigenfaces  ===================\n",
    "%  Run PCA and visualize the eigenvectors which are in this case eigenfaces\n",
    "%  We display the first 36 eigenfaces.\n",
    "%\n",
    "fprintf(['\\nRunning PCA on face dataset.\\n' ...\n",
    "         '(this might take a minute or two ...)\\n\\n']);\n",
    "\n",
    "%  Before running PCA, it is important to first normalize X by subtracting \n",
    "%  the mean value from each feature\n",
    "[X_norm, mu, sigma] = featureNormalize(X);\n",
    "\n",
    "%  Run PCA\n",
    "[U, S] = pca(X_norm);\n",
    "\n",
    "%  Visualize the top 36 eigenvectors found\n",
    "displayData(U(:, 1:36)');\n",
    "\n",
    "% fprintf('Program paused. Press enter to continue.\\n');\n",
    "% pause;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dimension reduction for face dataset.\n",
      "\n",
      "The projected data Z has a size of: \n",
      "5000 100 \n",
      "The projected data Z has a size of: 5000 100 \n"
     ]
    }
   ],
   "source": [
    "%% ============= Part 6: Dimension Reduction for Faces =================\n",
    "%  Project images to the eigen space using the top k eigenvectors \n",
    "%  If you are applying a machine learning algorithm \n",
    "fprintf('\\nDimension reduction for face dataset.\\n\\n');\n",
    "\n",
    "K = 100;\n",
    "Z = projectData(X_norm, U, K);\n",
    "\n",
    "fprintf('The projected data Z has a size of: ')\n",
    "fprintf('%d ', size(Z));\n",
    "\n",
    "% fprintf('\\n\\nProgram paused. Press enter to continue.\\n');\n",
    "% pause;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Visualizing the projected (reduced dimension) faces.\n",
      "\n",
      "error: U(0+1i,_): subscripts must be real (forgot to initialize i or j?)\n",
      "error: called from\n",
      "    recoverData at line 30 column 24\n",
      "error: X_rec(100,_): but X_rec has size 50x2\n"
     ]
    }
   ],
   "source": [
    "%% ==== Part 7: Visualization of Faces after PCA Dimension Reduction ====\n",
    "%  Project images to the eigen space using the top K eigen vectors and \n",
    "%  visualize only using those K dimensions\n",
    "%  Compare to the original input, which is also displayed\n",
    "\n",
    "fprintf('\\nVisualizing the projected (reduced dimension) faces.\\n\\n');\n",
    "\n",
    "K = 100;\n",
    "X_rec  = recoverData(Z, U, K);\n",
    "\n",
    "% Display normalized data\n",
    "subplot(1, 2, 1);\n",
    "displayData(X_norm(1:100,:));\n",
    "title('Original faces');\n",
    "axis square;\n",
    "\n",
    "% Display reconstructed data from only k eigenfaces\n",
    "subplot(1, 2, 2);\n",
    "displayData(X_rec(1:100,:));\n",
    "title('Recovered faces');\n",
    "axis square;\n",
    "\n",
    "% fprintf('Program paused. Press enter to continue.\\n');\n",
    "% pause;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "GNU Octave",
     "url": "https://www.gnu.org/software/octave/support.html"
    },
    {
     "text": "Octave Kernel",
     "url": "https://github.com/Calysto/octave_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "4.3.0+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
