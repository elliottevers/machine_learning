{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%% Machine Learning Online Class\n",
    "%  Exercise 5 | Regularized Linear Regression and Bias-Variance\n",
    "%\n",
    "%  Instructions\n",
    "%  ------------\n",
    "% \n",
    "%  This file contains code that helps you get started on the\n",
    "%  exercise. You will need to complete the following functions:\n",
    "%\n",
    "%     linearRegCostFunction.m\n",
    "%     learningCurve.m\n",
    "%     validationCurve.m\n",
    "%\n",
    "%  For this exercise, you will not need to change any code in this file,\n",
    "%  or any other files other than those mentioned above.\n",
    "%\n",
    "\n",
    "%% Initialization\n",
    "clear ; close all; clc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%plot gnuplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and Visualizing Data ...\n",
      "warning: load: '/Users/elliottevers/Documents/git-repos.nosync/machine_learning/labs/6/machine-learning-ex5/ex5/ex5data1.mat' found by searching load path\n"
     ]
    }
   ],
   "source": [
    "%% =========== Part 1: Loading and Visualizing Data =============\n",
    "%  We start the exercise by first loading and visualizing the dataset. \n",
    "%  The following code will load the dataset into your environment and plot\n",
    "%  the data.\n",
    "%\n",
    "\n",
    "% Load Training Data\n",
    "fprintf('Loading and Visualizing Data ...\\n')\n",
    "\n",
    "% Load from ex5data1: \n",
    "% You will have X, y, Xval, yval, Xtest, ytest in your environment\n",
    "dir_materials = '/Users/elliottevers/Documents/git-repos.nosync/machine_learning/labs/6/machine-learning-ex5/ex5';\n",
    "addpath(dir_materials);\n",
    "load ('ex5data1.mat');\n",
    "\n",
    "% m = Number of examples\n",
    "m = size(X, 1);\n",
    "\n",
    "% Plot training data\n",
    "plot(X, y, 'rx', 'MarkerSize', 10, 'LineWidth', 1.5);\n",
    "xlabel('Change in water level (x)');\n",
    "ylabel('Water flowing out of the dam (y)');\n",
    "\n",
    "% fprintf('Program paused. Press enter to continue.\\n');\n",
    "% pause;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "function [J, grad] = linearRegCostFunction(X, y, theta, lambda)\n",
    "%LINEARREGCOSTFUNCTION Compute cost and gradient for regularized linear \n",
    "%regression with multiple variables\n",
    "%   [J, grad] = LINEARREGCOSTFUNCTION(X, y, theta, lambda) computes the \n",
    "%   cost of using theta as the parameter for linear regression to fit the \n",
    "%   data points in X and y. Returns the cost in J and the gradient in grad\n",
    "\n",
    "% Initialize some useful values\n",
    "m = length(y); % number of training examples\n",
    "\n",
    "% You need to return the following variables correctly \n",
    "J = 0;\n",
    "grad = zeros(size(theta));\n",
    "\n",
    "% ====================== YOUR CODE HERE ======================\n",
    "% Instructions: Compute the cost and gradient of regularized linear \n",
    "%               regression for a particular choice of theta.\n",
    "%\n",
    "%               You should set J to the cost and grad to the gradient.\n",
    "%\n",
    "    \n",
    "h = X*theta;\n",
    "\n",
    "J = (1/(2*m))*sum((h - y) .^ 2) + (lambda/(2*m))*sum(theta(2:length(theta)) .^ 2);\n",
    "\n",
    "theta_without_bias = [0 ; theta(2)];\n",
    "\n",
    "grad = (1/m)*(X'*(h - y)) + (lambda/m)*theta_without_bias;\n",
    "\n",
    "% =========================================================================\n",
    "\n",
    "grad = grad(:);\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at theta = [1 ; 1]: 303.993192 \n",
      "(this value should be about 303.993192)\n"
     ]
    }
   ],
   "source": [
    "%% =========== Part 2: Regularized Linear Regression Cost =============\n",
    "%  You should now implement the cost function for regularized linear \n",
    "%  regression. \n",
    "%\n",
    "\n",
    "theta = [1 ; 1];\n",
    "J = linearRegCostFunction([ones(m, 1) X], y, theta, 1);\n",
    "\n",
    "fprintf(['Cost at theta = [1 ; 1]: %f '...\n",
    "         '\\n(this value should be about 303.993192)\\n'], J);\n",
    "\n",
    "% fprintf('Program paused. Press enter to continue.\\n');\n",
    "% pause;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient at theta = [1 ; 1]:  [-15.303016; 598.250744] \n",
      "(this value should be about [-15.303016; 598.250744])\n"
     ]
    }
   ],
   "source": [
    "%% =========== Part 3: Regularized Linear Regression Gradient =============\n",
    "%  You should now implement the gradient for regularized linear \n",
    "%  regression.\n",
    "%\n",
    "% dbstop in linearRegCostFunction 22\n",
    "theta = [1 ; 1];\n",
    "[J, grad] = linearRegCostFunction([ones(m, 1) X], y, theta, 1);\n",
    "\n",
    "fprintf(['Gradient at theta = [1 ; 1]:  [%f; %f] '...\n",
    "         '\\n(this value should be about [-15.303016; 598.250744])\\n'], ...\n",
    "         grad(1), grad(2));\n",
    "\n",
    "% fprintf('Program paused. Press enter to continue.\\n');\n",
    "% pause;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration     2 | Cost: 2.237391e+01\n"
     ]
    }
   ],
   "source": [
    "%% =========== Part 4: Train Linear Regression =============\n",
    "%  Once you have implemented the cost and gradient correctly, the\n",
    "%  trainLinearReg function will use your cost function to train \n",
    "%  regularized linear regression.\n",
    "% \n",
    "%  Write Up Note: The data is non-linear, so this will not give a great \n",
    "%                 fit.\n",
    "%\n",
    "\n",
    "%  Train linear regression with lambda = 0\n",
    "lambda = 0;\n",
    "[theta] = trainLinearReg([ones(m, 1) X], y, lambda);\n",
    "\n",
    "%  Plot fit over the data\n",
    "plot(X, y, 'rx', 'MarkerSize', 10, 'LineWidth', 1.5);\n",
    "xlabel('Change in water level (x)');\n",
    "ylabel('Water flowing out of the dam (y)');\n",
    "hold on;\n",
    "plot(X, [ones(m, 1) X]*theta, '--', 'LineWidth', 2)\n",
    "hold off;\n",
    "\n",
    "% fprintf('Program paused. Press enter to continue.\\n');\n",
    "% pause;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "function [error_train, error_val] = ...\n",
    "    learningCurve(X, y, Xval, yval, lambda)\n",
    "%LEARNINGCURVE Generates the train and cross validation set errors needed \n",
    "%to plot a learning curve\n",
    "%   [error_train, error_val] = ...\n",
    "%       LEARNINGCURVE(X, y, Xval, yval, lambda) returns the train and\n",
    "%       cross validation set errors for a learning curve. In particular, \n",
    "%       it returns two vectors of the same length - error_train and \n",
    "%       error_val. Then, error_train(i) contains the training error for\n",
    "%       i examples (and similarly for error_val(i)).\n",
    "%\n",
    "%   In this function, you will compute the train and test errors for\n",
    "%   dataset sizes from 1 up to m. In practice, when working with larger\n",
    "%   datasets, you might want to do this in larger intervals.\n",
    "%\n",
    "\n",
    "% Number of training examples\n",
    "m = size(X, 1);\n",
    "\n",
    "% You need to return these values correctly\n",
    "error_train = zeros(m, 1);\n",
    "error_val   = zeros(m, 1);\n",
    "\n",
    "% ====================== YOUR CODE HERE ======================\n",
    "% Instructions: Fill in this function to return training errors in \n",
    "%               error_train and the cross validation errors in error_val. \n",
    "%               i.e., error_train(i) and \n",
    "%               error_val(i) should give you the errors\n",
    "%               obtained after training on i examples.\n",
    "%\n",
    "% Note: You should evaluate the training error on the first i training\n",
    "%       examples (i.e., X(1:i, :) and y(1:i)).\n",
    "%\n",
    "%       For the cross-validation error, you should instead evaluate on\n",
    "%       the _entire_ cross validation set (Xval and yval).\n",
    "%\n",
    "% Note: If you are using your cost function (linearRegCostFunction)\n",
    "%       to compute the training and cross validation error, you should \n",
    "%       call the function with the lambda argument set to 0. \n",
    "%       Do note that you will still need to use lambda when running\n",
    "%       the training to obtain the theta parameters.\n",
    "%\n",
    "% Hint: You can loop over the examples with the following:\n",
    "%\n",
    "%       for i = 1:m\n",
    "%           % Compute train/cross validation errors using training examples \n",
    "%           % X(1:i, :) and y(1:i), storing the result in \n",
    "%           % error_train(i) and error_val(i)\n",
    "%           ....\n",
    "%           \n",
    "%       end\n",
    "%\n",
    "\n",
    "% ---------------------- Sample Solution ----------------------\n",
    "\n",
    "for i = 1:m\n",
    "    X_sub = X(1:i, :);\n",
    "    y_sub = y(1:i); \n",
    "\n",
    "    theta = trainLinearReg(X_sub, y_sub, lambda);\n",
    "\n",
    "    error_train(i) = linearRegCostFunction(X_sub, y_sub, theta, 0);\n",
    "    error_val(i) = linearRegCostFunction(Xval, yval, theta, 0);\n",
    "end\n",
    "\n",
    "\n",
    "% -------------------------------------------------------------\n",
    "\n",
    "% =========================================================================\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 102 column 12\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "\n",
      "Iteration     3 | Cost: 9.860761e-32\n",
      "Iteration     7 | Cost: 3.286595e+00\n",
      "Iteration    25 | Cost: 2.842678e+00\n",
      "Iteration    29 | Cost: 1.315405e+01\n",
      "Iteration    36 | Cost: 1.944396e+01\n",
      "Iteration    13 | Cost: 2.009852e+01\n",
      "Iteration    30 | Cost: 1.817286e+01\n",
      "Iteration     8 | Cost: 2.260941e+01\n",
      "Iteration    17 | Cost: 2.326146e+01\n",
      "Iteration    17 | Cost: 2.431725e+01\n",
      "Iteration     2 | Cost: 2.237391e+01\n",
      "# Training Examples\tTrain Error\tCross Validation Error\n",
      "  \t1\t\t0.000000\t205.121096\n",
      "  \t2\t\t0.000000\t110.300366\n",
      "  \t3\t\t3.286595\t45.010231\n",
      "  \t4\t\t2.842678\t48.368911\n",
      "  \t5\t\t13.154049\t35.865165\n",
      "  \t6\t\t19.443963\t33.829962\n",
      "  \t7\t\t20.098522\t31.970986\n",
      "  \t8\t\t18.172859\t30.862446\n",
      "  \t9\t\t22.609405\t31.135998\n",
      "  \t10\t\t23.261462\t28.936207\n",
      "  \t11\t\t24.317250\t29.551432\n",
      "  \t12\t\t22.373906\t29.433818\n"
     ]
    }
   ],
   "source": [
    "%% =========== Part 5: Learning Curve for Linear Regression =============\n",
    "%  Next, you should implement the learningCurve function. \n",
    "%\n",
    "%  Write Up Note: Since the model is underfitting the data, we expect to\n",
    "%                 see a graph with \"high bias\" -- Figure 3 in ex5.pdf \n",
    "%\n",
    "\n",
    "lambda = 0;\n",
    "[error_train, error_val] = ...\n",
    "    learningCurve([ones(m, 1) X], y, ...\n",
    "                  [ones(size(Xval, 1), 1) Xval], yval, ...\n",
    "                  lambda);\n",
    "\n",
    "plot(1:m, error_train, 1:m, error_val);\n",
    "title('Learning curve for linear regression')\n",
    "legend('Train', 'Cross Validation')\n",
    "xlabel('Number of training examples')\n",
    "ylabel('Error')\n",
    "axis([0 13 0 150])\n",
    "\n",
    "fprintf('# Training Examples\\tTrain Error\\tCross Validation Error\\n');\n",
    "for i = 1:m\n",
    "    fprintf('  \\t%d\\t\\t%f\\t%f\\n', i, error_train(i), error_val(i));\n",
    "end\n",
    "\n",
    "% fprintf('Program paused. Press enter to continue.\\n');\n",
    "% pause;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "function [X_poly] = polyFeatures(X, p)\n",
    "%POLYFEATURES Maps X (1D vector) into the p-th power\n",
    "%   [X_poly] = POLYFEATURES(X, p) takes a data matrix X (size m x 1) and\n",
    "%   maps each example into its polynomial features where\n",
    "%   X_poly(i, :) = [X(i) X(i).^2 X(i).^3 ...  X(i).^p];\n",
    "%\n",
    "\n",
    "\n",
    "% You need to return the following variables correctly.\n",
    "X_poly = zeros(numel(X), p);\n",
    "\n",
    "% ====================== YOUR CODE HERE ======================\n",
    "% Instructions: Given a vector X, return a matrix X_poly where the p-th \n",
    "%               column of X contains the values of X to the p-th power.\n",
    "%\n",
    "% \n",
    "\n",
    "for i = 1:size(X, 1)\n",
    "    for j = 1:p\n",
    "        X_poly(i, j) = X(i)^j;\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "% =========================================================================\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Training Example 1:\n",
      "  1.000000  \n",
      "  -0.362141  \n",
      "  -0.755087  \n",
      "  0.182226  \n",
      "  -0.706190  \n",
      "  0.306618  \n",
      "  -0.590878  \n",
      "  0.344516  \n",
      "  -0.508481  \n"
     ]
    }
   ],
   "source": [
    "%% =========== Part 6: Feature Mapping for Polynomial Regression =============\n",
    "%  One solution to this is to use polynomial regression. You should now\n",
    "%  complete polyFeatures to map each example into its powers\n",
    "%\n",
    "\n",
    "p = 8;\n",
    "\n",
    "% Map X onto Polynomial Features and Normalize\n",
    "X_poly = polyFeatures(X, p);\n",
    "[X_poly, mu, sigma] = featureNormalize(X_poly);  % Normalize\n",
    "X_poly = [ones(m, 1), X_poly];                   % Add Ones\n",
    "\n",
    "% Map X_poly_test and normalize (using mu and sigma)\n",
    "X_poly_test = polyFeatures(Xtest, p);\n",
    "X_poly_test = bsxfun(@minus, X_poly_test, mu);\n",
    "X_poly_test = bsxfun(@rdivide, X_poly_test, sigma);\n",
    "X_poly_test = [ones(size(X_poly_test, 1), 1), X_poly_test];         % Add Ones\n",
    "\n",
    "% Map X_poly_val and normalize (using mu and sigma)\n",
    "X_poly_val = polyFeatures(Xval, p);\n",
    "X_poly_val = bsxfun(@minus, X_poly_val, mu);\n",
    "X_poly_val = bsxfun(@rdivide, X_poly_val, sigma);\n",
    "X_poly_val = [ones(size(X_poly_val, 1), 1), X_poly_val];           % Add Ones\n",
    "\n",
    "fprintf('Normalized Training Example 1:\\n');\n",
    "fprintf('  %f  \\n', X_poly(1, :));\n",
    "\n",
    "% fprintf('\\nProgram paused. Press enter to continue.\\n');\n",
    "% pause;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration   200 | Cost: 1.407350e-01\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 102 column 12\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 102 column 12\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 124 column 8\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "\n",
      "Iteration    29 | Cost: 6.573841e-32\n",
      "Iteration     9 | Cost: 1.839845e-27\n",
      "Iteration   200 | Cost: 3.958283e-11\n",
      "Iteration   200 | Cost: 1.281353e-05\n",
      "Iteration   200 | Cost: 3.813107e-02\n",
      "Iteration   200 | Cost: 7.372734e-02\n",
      "warning: division by zero\n",
      "warning: called from\n",
      "    fmincg at line 102 column 12\n",
      "    trainLinearReg at line 19 column 7\n",
      "    learningCurve at line 60 column 11\n",
      "Iteration   200 | Cost: 1.713767e-01\n",
      "Iteration   200 | Cost: 7.556438e-02\n",
      "Iteration   200 | Cost: 5.974299e-02\n",
      "Iteration   200 | Cost: 1.407350e-01\n",
      "Polynomial Regression (lambda = 0.000000)\n",
      "\n",
      "# Training Examples\tTrain Error\tCross Validation Error\n",
      "  \t1\t\t0.000000\t160.721900\n",
      "  \t2\t\t0.000000\t160.121510\n",
      "  \t3\t\t0.000000\t61.754825\n",
      "  \t4\t\t0.000000\t61.928895\n",
      "  \t5\t\t0.000000\t6.598034\n",
      "  \t6\t\t0.000013\t10.571111\n",
      "  \t7\t\t0.038131\t8.410782\n",
      "  \t8\t\t0.073727\t5.735125\n",
      "  \t9\t\t0.171377\t7.220003\n",
      "  \t10\t\t0.075564\t7.312403\n",
      "  \t11\t\t0.059743\t12.979983\n",
      "  \t12\t\t0.140735\t16.188133\n"
     ]
    }
   ],
   "source": [
    "%% =========== Part 7: Learning Curve for Polynomial Regression =============\n",
    "%  Now, you will get to experiment with polynomial regression with multiple\n",
    "%  values of lambda. The code below runs polynomial regression with \n",
    "%  lambda = 0. You should try running the code with different values of\n",
    "%  lambda to see how the fit and learning curve change.\n",
    "%\n",
    "\n",
    "lambda = 0;\n",
    "[theta] = trainLinearReg(X_poly, y, lambda);\n",
    "\n",
    "% Plot training data and fit\n",
    "figure(1);\n",
    "plot(X, y, 'rx', 'MarkerSize', 10, 'LineWidth', 1.5);\n",
    "plotFit(min(X), max(X), mu, sigma, theta, p);\n",
    "xlabel('Change in water level (x)');\n",
    "ylabel('Water flowing out of the dam (y)');\n",
    "title (sprintf('Polynomial Regression Fit (lambda = %f)', lambda));\n",
    "\n",
    "figure(2);\n",
    "[error_train, error_val] = ...\n",
    "    learningCurve(X_poly, y, X_poly_val, yval, lambda);\n",
    "plot(1:m, error_train, 1:m, error_val);\n",
    "\n",
    "title(sprintf('Polynomial Regression Learning Curve (lambda = %f)', lambda));\n",
    "xlabel('Number of training examples')\n",
    "ylabel('Error')\n",
    "axis([0 13 0 100])\n",
    "legend('Train', 'Cross Validation')\n",
    "\n",
    "fprintf('Polynomial Regression (lambda = %f)\\n\\n', lambda);\n",
    "fprintf('# Training Examples\\tTrain Error\\tCross Validation Error\\n');\n",
    "for i = 1:m\n",
    "    fprintf('  \\t%d\\t\\t%f\\t%f\\n', i, error_train(i), error_val(i));\n",
    "end\n",
    "\n",
    "% fprintf('Program paused. Press enter to continue.\\n');\n",
    "% pause;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "function [lambda_vec, error_train, error_val] = ...\n",
    "    validationCurve(X, y, Xval, yval)\n",
    "%VALIDATIONCURVE Generate the train and validation errors needed to\n",
    "%plot a validation curve that we can use to select lambda\n",
    "%   [lambda_vec, error_train, error_val] = ...\n",
    "%       VALIDATIONCURVE(X, y, Xval, yval) returns the train\n",
    "%       and validation errors (in error_train, error_val)\n",
    "%       for different values of lambda. You are given the training set (X,\n",
    "%       y) and validation set (Xval, yval).\n",
    "%\n",
    "\n",
    "% Selected values of lambda (you should not change this)\n",
    "lambda_vec = [0 0.001 0.003 0.01 0.03 0.1 0.3 1 3 10]';\n",
    "\n",
    "% You need to return these variables correctly.\n",
    "error_train = zeros(length(lambda_vec), 1);\n",
    "error_val = zeros(length(lambda_vec), 1);\n",
    "\n",
    "% ====================== YOUR CODE HERE ======================\n",
    "% Instructions: Fill in this function to return training errors in \n",
    "%               error_train and the validation errors in error_val. The \n",
    "%               vector lambda_vec contains the different lambda parameters \n",
    "%               to use for each calculation of the errors, i.e, \n",
    "%               error_train(i), and error_val(i) should give \n",
    "%               you the errors obtained after training with \n",
    "%               lambda = lambda_vec(i)\n",
    "%\n",
    "% Note: You can loop over lambda_vec with the following:\n",
    "%\n",
    "%       for i = 1:length(lambda_vec)\n",
    "%           lambda = lambda_vec(i);\n",
    "%           % Compute train / val errors when training linear \n",
    "%           % regression with regularization parameter lambda\n",
    "%           % You should store the result in error_train(i)\n",
    "%           % and error_val(i)\n",
    "%           ....\n",
    "%           \n",
    "%       end\n",
    "%\n",
    "%\n",
    "\n",
    "\n",
    "\n",
    "for i = 1:length(lambda_vec)\n",
    "    theta = trainLinearReg(X, y, lambda_vec(i));\n",
    "\n",
    "    error_train(i) = linearRegCostFunction(X, y, theta, 0);\n",
    "    \n",
    "    error_val(i) = linearRegCostFunction(Xval, yval, theta, 0);\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "% =========================================================================\n",
    "\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration   200 | Cost: 1.407350e-01\n",
      "Iteration   200 | Cost: 1.950934e-01\n",
      "Iteration   200 | Cost: 2.575124e-01\n",
      "Iteration   200 | Cost: 3.850690e-01\n",
      "Iteration   200 | Cost: 6.692749e-01\n",
      "Iteration   161 | Cost: 1.443470e+00\n",
      "Iteration   109 | Cost: 3.101591e+00\n",
      "Iteration    65 | Cost: 7.268148e+00\n",
      "Iteration    38 | Cost: 1.586769e+01\n",
      "Iteration    20 | Cost: 3.337220e+01\n",
      "lambda\t\tTrain Error\tValidation Error\n",
      " 0.000000\t0.140735\t16.188133\n",
      " 0.001000\t0.166534\t19.368697\n",
      " 0.003000\t0.198023\t20.200514\n",
      " 0.010000\t0.221988\t17.019779\n",
      " 0.030000\t0.281851\t12.828854\n",
      " 0.100000\t0.459318\t7.587013\n",
      " 0.300000\t0.921760\t4.636833\n",
      " 1.000000\t2.076188\t4.260625\n",
      " 3.000000\t4.901351\t3.822907\n",
      " 10.000000\t16.092213\t9.945508\n"
     ]
    }
   ],
   "source": [
    "%% =========== Part 8: Validation for Selecting Lambda =============\n",
    "%  You will now implement validationCurve to test various values of \n",
    "%  lambda on a validation set. You will then use this to select the\n",
    "%  \"best\" lambda value.\n",
    "%\n",
    "\n",
    "[lambda_vec, error_train, error_val] = ...\n",
    "    validationCurve(X_poly, y, X_poly_val, yval);\n",
    "\n",
    "close all;\n",
    "plot(lambda_vec, error_train, lambda_vec, error_val);\n",
    "legend('Train', 'Cross Validation');\n",
    "xlabel('lambda');\n",
    "ylabel('Error');\n",
    "\n",
    "fprintf('lambda\\t\\tTrain Error\\tValidation Error\\n');\n",
    "for i = 1:length(lambda_vec)\n",
    "\tfprintf(' %f\\t%f\\t%f\\n', ...\n",
    "            lambda_vec(i), error_train(i), error_val(i));\n",
    "end\n",
    "\n",
    "% fprintf('Program paused. Press enter to continue.\\n');\n",
    "% pause;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "GNU Octave",
     "url": "https://www.gnu.org/software/octave/support.html"
    },
    {
     "text": "Octave Kernel",
     "url": "https://github.com/Calysto/octave_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "4.3.0+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
